---
title: Un assistente nutrizionale LLM usando RAG e OpenAI
date: 2025-09-15
description: Come implementare un LLM pronto per la produzione che restituisce informazioni nutrizionali sui cibi usando RAG
image: /images/articles/nutritional-rag-llm.jpg
alt: LLM nutrizionale RAG usando API OpenAI
tags: ['llm', 'rag', 'openai']
locale: 'it'
---

### Contesto

I **Large Language Models** e l'Intelligenza Artificiale Generativa stanno diventando sempre più prevalenti, e hanno profondamente cambiato le nostre vite. Per noi come ingegneri del software, questo significa che i nostri lavori si stanno evolvendo rapidamente. Ora abbiamo molti strumenti a nostra disposizione, dalle revisioni automatiche del codice agli agenti di codifica intelligenti, che ci assistono nelle nostre attività quotidiane.

Considerando che l'ecosistema è enorme e cambia rapidamente, è facile vedere come l'AI e gli LLM faranno parte delle nostre vite per molti anni a venire. Pertanto, è importante avere una chiara comprensione delle capacità di questi strumenti per ottenere il massimo da essi.

Per queste ragioni, negli ultimi mesi, ho seguito un corso sull'Ingegneria LLM su <a href="https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/" target="_blank">Udemy</a> per iniziare a capire gli LLM: come funzionano, come interagire con essi, come creare un'applicazione pronta per la produzione e conveniente.

### Il progetto e le sfide

Quando sto imparando qualcosa di nuovo, il mio approccio tipico è costruire qualcosa per ottenere una migliore comprensione dell'argomento. Durante il corso, ho subito capito quale poteva essere il mio primo progetto: un LLM capace di restituire informazioni nutrizionali sui cibi. Sono sempre stato appassionato di salute e alimentazione, quindi questa era un'opportunità per costruire un assistente capace che potesse aiutarmi a contare i miei macronutrienti e calorie giornaliere.

La sfida principale è relativa al costo dell'applicazione. Mentre basterebbero solo pochi minuti per scrivere il prompt giusto e ottenere una risposta appropriata da GPT, l'API OpenAI ha un costo. Inoltre, non è garantito che gli LLM siano stati pre-addestrati con fatti nutrizionali. Questo ha portato a due scelte principali quando si considera la strategia giusta:

1. **Retrieval-Augmented Generation (RAG)**: questa è una tecnica in cui un prompt viene arricchito con più contesto prima di essere inviato all'LLM. In questo modo, l'LLM può estrarre le informazioni giuste necessarie all'utente da un contesto più ampio e arricchito;
2. **Fine-tuning**: questo è il processo di prendere un modello pre-addestrato e specializzarlo per un dominio specifico.

Entrambe le soluzioni hanno vantaggi e svantaggi. Un RAG è più facile da implementare e la sua fonte di dati è più semplice da aggiornare, ma dipende strettamente dalla qualità dei dati recuperati. D'altra parte, un modello fine-tuned potrebbe essere più accurato, ma l'addestramento richiede molto tempo e risorse, e aggiornare il modello con nuovi dati è molto difficile.

Considerando che la soluzione dovrebbe avere il minor impatto possibile sui costi e le risorse, ho deciso di implementare un RAG.

### Preprocessing del dataset

Prima di iniziare, è importante trovare il dataset giusto per il progetto. Dopo alcune ricerche, ho deciso di adottare un <a href="https://www.kaggle.com/datasets/shrutisaxena/food-nutrition-dataset" target="_blank">dataset Kaggle</a> che conteneva tutte le informazioni di cui avevo bisogno. Per ogni cibo, considerando una porzione di 100g, fornisce informazioni su:

- carboidrati
- proteine
- grassi
- zuccheri
- fibre
- calorie

Il dataset non aveva bisogno di altro preprocessing oltre alla selezione e rinominazione delle colonne rilevanti. A questo punto, il dataset era pronto. Se vuoi vedere come è stato fatto, puoi fare riferimento al relativo <a href="https://github.com/federicoibba/nutritional-information-rag/blob/main/notebooks/0_dataset-food.ipynb" target="_blank">Jupyter Notebook</a>.

### Vector store

In un sistema RAG, un prompt viene arricchito con contesto da una fonte di dati esterna. Questi dati vengono convertiti in vettori numerici, un processo chiamato **vettorizzazione**. Questi vettori vengono poi memorizzati e recuperati, permettendo al sistema di comprendere e lavorare con i dati basandosi sul loro significato semantico piuttosto che solo su parole chiave.

Ci sono molte opzioni disponibili quando si sceglie il vector store giusto, alcune di esse sono:

- _database self-hosted_: soluzioni come <a href="https://www.trychroma.com/" target="_blank">Chroma</a> o <a href="https://milvus.io/" target="_blank">Milvus</a> permettono la creazione di store in-memory che facilitano la prototipazione;
- _servizi cloud gestiti_: ci sono piattaforme hosted come MongoDB che offrono una funzionalità di ricerca vettoriale nativa all'interno del servizio cloud;
- _estensioni per database tradizionali_: database come PostgreSQL e Redis offrono integrazione per memorizzare e recuperare vettori.

Ho deciso di andare con MongoDB. Il suo tier gratuito di storage (512MB) è più che sufficiente per il mio caso d'uso (alla fine, ho memorizzato solo 36MB di dati), la documentazione è eccellente, ed è davvero facile da integrare. A questo punto, quello che serve è solo:

- popolare la collezione con i vettori;
- creare l'indice di ricerca vettoriale per recuperare i vettori.

Per alcuni spoiler, puoi fare riferimento al relativo <a href="https://github.com/federicoibba/nutritional-information-rag/blob/main/notebooks/1_create_vectorstore.ipynb" target="_blank">Jupyter Notebook</a>, dove spiego come funziona tutto.

#### Popolare la collezione

Prima di tutto, i documenti che abbiamo devono essere trasformati in vettori, quindi ogni riga del dataset viene codificata usando un **SentenceTransformer**.  
Con documenti più grandi, un passo importante è dividerli in chunk, decidendo su una finestra di contesto sovrapposta per aiutare con il recupero dell'indice. Tuttavia, poiché i documenti sono piccoli, questo passo non è necessario qui.

Per popolare la collezione, è necessario il seguente codice:

```python
client = MongoClient(uri)
collection = client[DB_NAME][COLLECTION_NAME]
result = collection.insert_many(docs_to_insert)
```

#### Creare l'indice del database

Per interrogare il nostro database RAG, viene creato un Vector Search Index all'interno di MongoDB. Come spiega la <a href="https://www.mongodb.com/docs/atlas/atlas-vector-search/rag/#use-mongodb-vector-search-to-retrieve-documents.-4" target="_blank">documentazione Atlas</a>, questo è come viene creato:

```python
from pymongo.operations import SearchIndexModel
import time

index_name="vector_index"
search_index_model = SearchIndexModel(
  definition = {
    "fields": [
      {
        "type": "vector",
        "numDimensions": 384,
        "path": "embedding",
        "similarity": "cosine"
      }
    ]
  },
  name = index_name,
  type = "vectorSearch"
)
collection.create_search_index(model=search_index_model)
```

Nota che l'indice deve conoscere la dimensione del vettore (384 in questo esempio) e la metrica di similarità (similarità coseno in questo caso) per interrogare i dati efficacemente.

### Notebook Open AI

L'implementazione dei concetti discussi in precedenza può essere trovata in questo <a href="https://github.com/federicoibba/nutritional-information-rag/blob/main/notebooks/2.0_open-ai.ipynb" target="_blank">notebook</a>.  
Il processo RAG coinvolge l'interrogazione di MongoDB con un dato elemento alimentare, e i risultati vengono poi passati al modello **gpt-4o-mini**. Come richiesto nel prompt, il modello restituisce un oggetto JSON, che può essere facilmente consumato da un servizio RESTful. Per esempio, un input di **pesce salmone** produrrà il seguente output:

```json
{
  "protein": 22.56,
  "carbohydrates": 0,
  "fats": 5.57,
  "calories": 140,
  "sugars": 0,
  "fibers": 0
}
```

### Rilasciare il RAG come API Restful Serverless

Potresti aver pensato che questa fosse la fine dell'articolo, ma il punto principale di tutto questo era capire come un'applicazione pronta per la produzione potesse essere efficacemente rilasciata e usata nel mercato.  
Per raggiungere questo obiettivo, ho usato <a href="https://modal.com" target="_blank">modal.com</a>, una piattaforma di calcolo serverless progettata per applicazioni AI e Machine Learning. Il loro tier gratuito era sufficiente per i miei esperimenti (danno da 5 a 30 dollari di crediti gratuiti mensili), quindi andava bene.  
Ecco il <a href="https://github.com/federicoibba/nutritional-information-rag/blob/main/services/openai-api.py" target="_blank">risultato finale</a>, un servizio facilmente deployato su internet e pronto per essere usato per un'applicazione nutrizionale. Quello che ho fatto qui è solo prendere i blocchi di codice dai notebook e mettere tutto insieme usando le API Modal e la nomenclatura FastAPI.  
In questo caso, per evitare di esporre la mia chiave API OpenAI, ho aggiunto un header chiamato **X-Open-AI-Api-Key** che chiunque può riempire con la propria chiave API appropriata. Questo è un esempio di richiesta che restituirà il JSON dichiarato sopra:

```bash
curl --location 'https://ibbus93--nutritional-rag-service-openai-nutritionalragse-f9d7ea.modal.run' \
--header 'Content-Type: application/json' \
--header 'X-Open-AI-Api-Key: sk-proj-your-api-key' \
--data '{
    "description": "Pesce salmone"
}'
```

In ogni caso, per maggiori dettagli sull'implementazione e l'esempio, per favore fai riferimento al mio <a href="https://github.com/federicoibba/nutritional-information-rag/" target="_blank">progetto repository</a>.

### Considerazioni finali

Ho passato settimane a studiare il mondo degli LLM su Udemy e cercando di applicare i concetti a questo divertente progetto RAG. Usando il potere fornito dagli LLM, le applicazioni sono infinite, limitate solo dall'immaginazione umana.  
Oltre al RAG basato su OpenAI descritto qui, ho anche testato l'applicazione con modelli open-source come Llama e Qwen. Questo approccio potrebbe potenzialmente ridurre i costi rispetto all'uso dell'API di OpenAI, ma richiederebbe l'introduzione di diversi nuovi concetti (come transformer e tokenizer). Credo anche che l'accuratezza della soluzione possa essere leggermente migliorata, quindi salverò quella discussione per un articolo futuro.  
Se sei arrivato fin qui, grazie per aver letto. Apprezzo la tua attenzione! :)

### Bibliografia

- [Progetto repository](https://github.com/federicoibba/nutritional-information-rag/)
- [Fonte dataset](https://www.kaggle.com/datasets/shrutisaxena/food-nutrition-dataset)
- [RAG con Atlas](https://www.mongodb.com/docs/atlas/atlas-vector-search/rag/#std-label-avs-rag)
- [Cos'è Retrieval Augmented Generation](https://www.databricks.com/glossary/retrieval-augmented-generation-rag)
- [Spiegazione RAG HuggingFace](https://huggingface.co/learn/cookbook/advanced_rag)
- [Documentazione Modal.com](https://modal.com/docs)
- Foto articolo di <a href="https://unsplash.com/@bamin?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash" target="_blank">Pierre Bamin</a> su <a href="https://unsplash.com/photos/used-paint-brushes-RwccoChIGB8?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash" target="_blank">Unsplash</a>